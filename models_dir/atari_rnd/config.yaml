distributed:
    backend: gloo
    world_size: 32
    master_addr: localhost
    master_port: '12345'
algo:
    cls_name: PPO
    seg_len: 128
    opt_epochs: 4
    learner_batch_size: 32
    clip_param_init: 0.1
    clip_param_final: 0.1
    ent_coef_init: 0.001
    ent_coef_final: 0.001
    vf_loss_coef: 0.5
    vf_loss_cls: MSELoss
    vf_loss_clipping: False
    vf_simple_weighting: True  # Burda 2018 src code weights all vf losses same
    gae_lambda:
        extrinsic: 0.95
        intrinsic_rnd: 0.95
    gae_extra_steps: 0
    discount_gamma:
        extrinsic: 0.999
        intrinsic_rnd: 0.99
    use_dones:
        extrinsic: True
        intrinsic_rnd: False
    standardize_adv: False
    reward_weights:
        extrinsic: 2.0
        intrinsic_rnd: 1.0
    use_pcgrad: False
    stats_memory_len: 100
    checkpoint_frequency: 100
    non_learning_steps: 409600  # RNDWrapper nonlearning steps * world_size
    max_steps: 500000000        # 0.5B
env:
    wrappers:
        TimeLimitWrapper: {max_episode_steps: 18000}
        StickyActionsWrapper: {stick_prob: 0.25}
        MaxAndSkipWrapper: {num_skip: 4, apply_max: True}
        ResizeWrapper: {target_height: 84, target_width: 84, use_grayscale: True}
        ActionResetWrapper: {action_reset_sequence: [1, 2]}
        ClipRewardWrapper: {low: -1.0, high: 1.0}
        ScaleObservationsWrapper: {scale_factor: 0.00392156862745098}  # 1/255
        FrameStackWrapper: {num_stack: 4, lazy: False}
        RandomNetworkDistillationWrapper:
            rnd_optimizer_cls_name: Adam
            rnd_optimizer_args: {lr: 0.0001, eps: 0.00001}
            world_size: 32
            widening: 1
            non_learning_steps: 12800
        NormalizeRewardWrapper:
            gamma: 0.99
            world_size: 32
            key: intrinsic_rnd
networks:
    policy_net:
        preprocessing:
            ToChannelMajor: {}
        architecture:
            cls_name: NatureCNN
            cls_args: {img_channels: 4, ortho_init: True}
        predictors:
            policy:
                cls_name: LinearCategoricalPolicyHead
                cls_args: {num_features: 512, ortho_init: True}
            value_extrinsic:
                cls_name: LinearValueHead
                cls_args: {num_features: 512, ortho_init: True}
            value_intrinsic_rnd:
                cls_name: LinearValueHead
                cls_args: {num_features: 512, ortho_init: True}
        optimizer:
            cls_name: Adam
            cls_args: {lr: 0.0001, eps: 0.00001}
        scheduler:
            cls_name: None
            cls_args: {}
    value_net:
        use_shared_architecture: True