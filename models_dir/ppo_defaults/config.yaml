backend: gloo
world_size: 8
master_addr: localhost
master_port: '12345'
algo:
    cls_name: PPO
    segment_length: 128
    opt_epochs: 3
    learner_batch_size: 32
    clip_param: 0.1
    ent_coef: 0.01
    vf_loss_coef: 1.0
    gae_lambda:
        extrinsic: 0.95
    discount_gamma:
        extrinsic: 0.99
    checkpoint_frequency: 100
    max_steps: 11000000
env:
    id: 'PongNoFrameskip-v4'
    wrappers:
        AtariWrapper: {}
        DeepmindWrapper: {frame_stack: False}
policy_net:
    preprocessing:
        ToChannelMajor: {}
    architecture:
        cls_name: AsyncCNN
        cls_args: {img_channels: 1}
    predictors:
        policy:
            cls_name: LinearCategoricalPolicyHead
            cls_args: {num_features: 256}
        value_extrinsic:
            cls_name: LinearValueHead
            cls_args: {num_features: 256}
    optimizer:
        cls_name: Adam
        cls_args: {lr: 0.00025, eps: 0.00001}
    scheduler:
        cls_name: OneCycleLR
        cls_args:
            max_lr: 0.00025
            total_steps: 11000000
            pct_start: 0.0,
            anneal_strategy: linear
            cycle_momentum: False
            div_factor: 1.0
value_net:
    use_shared_architecture: True